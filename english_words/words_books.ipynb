{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PyDictionary import PyDictionary\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "import json\n",
    "from difflib import get_close_matches\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import english dictionary with level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Oxford 5000â„¢ (American English)\n",
      "\n",
      "The Oxford 5000 is an expanded core word list for advanced learners of English. As well as the Oxford \n",
      "3000, it includes an additional 2000 words for learners at B2-C1 level, which are listed here.\n",
      "\n",
      "abolish v. C1\n",
      "abortion n. C1\n",
      "absence n. C1\n",
      "absent adj. C1\n",
      "absorb v. B2\n",
      "abstract adj. B2\n",
      "absurd adj. C1\n",
      "abuse n., v. C1\n",
      "academy n. C1\n",
      "accelerate v. C1\n",
      "accent n. B2\n",
      "acceptance n. C1\n",
      "accessible adj. C1\n",
      "accidentally adv. B2\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Convert pdf content from a file path to text\n",
    "'''\n",
    "\n",
    "def convert_pdf_to_txt(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "\n",
    "    with io.StringIO() as retstr:\n",
    "        with TextConverter(rsrcmgr, retstr, codec=codec,\n",
    "                           laparams=laparams) as device:\n",
    "            with open(path, 'rb') as fp:\n",
    "                interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "                password = \"\"\n",
    "                maxpages = 0\n",
    "                caching = True\n",
    "                pagenos = set()\n",
    "\n",
    "                for page in PDFPage.get_pages(fp,\n",
    "                                              pagenos,\n",
    "                                              maxpages=maxpages,\n",
    "                                              password=password,\n",
    "                                              caching=caching,\n",
    "                                              check_extractable=True):\n",
    "                    interpreter.process_page(page)\n",
    "                return retstr.getvalue()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    text = convert_pdf_to_txt('American_Oxford_5000.pdf')\n",
    "    print(text[:455])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abolish</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abortion</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word Level\n",
       "0   abolish    C1\n",
       "1  abortion    C1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Creating a array with the word name and level\n",
    "'''\n",
    "words = [] \n",
    "\n",
    "for line in text.split('\\n'):\n",
    "    words.append(line)\n",
    "    \n",
    "for word in range(5):\n",
    "    words.pop(0)\n",
    "    \n",
    "formattedWords = []    \n",
    "for word in words:\n",
    "    if(len(word.split(' ')) < 3):\n",
    "        continue\n",
    "    else:\n",
    "        formattedWords.append({'word': word.split(' ')[0], 'Level': word.split(' ')[2][-2:]})\n",
    "\n",
    "df_word_level = pd.DataFrame(formattedWords)\n",
    "df_word_level.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import english dictionary with meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter word: \n",
      "The word doesn't exist. Please double check it.\n",
      "Press ENTER to exit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data from json file\n",
    "# in python dictionary\n",
    "data = json.load(open(\"dictionary.json\"))\n",
    "  \n",
    "def translate(w):\n",
    "    # converts to lower case\n",
    "    w = w.lower()\n",
    "  \n",
    "    if w in data:\n",
    "        return data[w]\n",
    "    # for getting close matches of word\n",
    "    elif len(get_close_matches(w, data.keys())) > 0:             \n",
    "        yn = input(\"Did you mean % s instead? Enter Y if yes, or N if no: \" % get_close_matches(w, data.keys())[0])\n",
    "        yn = yn.lower()\n",
    "        if yn == \"y\":\n",
    "            return data[get_close_matches(w, data.keys())[0]]\n",
    "        elif yn == \"n\":\n",
    "            return \"The word doesn't exist. Please double check it.\"\n",
    "        else:\n",
    "            return \"We didn't understand your entry.\"\n",
    "    else:\n",
    "        return \"The word doesn't exist. Please double check it.\"\n",
    "  \n",
    "\n",
    "word = input(\"Enter word: \")\n",
    "output = translate(word)\n",
    "\n",
    "if type(output) == list:\n",
    "    for item in output:\n",
    "        print(item)\n",
    "else:\n",
    "        print(output)\n",
    "input('Press ENTER to exit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import kindle notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = load_workbook(filename='Lean_In_ Women_Work.xlsx', \n",
    "                   read_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = wb['kindle']\n",
    "\n",
    "# Read the cell values into a list of lists\n",
    "data_rows = []\n",
    "for row in ws['D9':'D150']:\n",
    "    data_cols = []\n",
    "    for cell in row:\n",
    "        data_cols.append(cell.value)\n",
    "    data_rows.append(data_cols)\n",
    "\n",
    "# Transform into dataframe\n",
    "df_words_book = pd.DataFrame(data_rows)\n",
    "df_words_book['chapter'] = 1\n",
    "df_words_book = df_words_book.rename(columns = {0: 'word'}, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>chapter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lumps</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>propped up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  chapter\n",
       "0       lumps        1\n",
       "1  propped up        1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words_book.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate words with level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>chapter</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lumps</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>propped up</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sprinted</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lumbering</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>strewn</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  chapter Level\n",
       "0       lumps        1   NaN\n",
       "1  propped up        1   NaN\n",
       "2    sprinted        1   NaN\n",
       "3   lumbering        1   NaN\n",
       "4      strewn        1   NaN"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.merge(df_words_book,df_word_level,on='word',how='left')\n",
    "df_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_df_to_excel(filename, df, sheet_name='Sheet1', startrow=None,\n",
    "                       truncate_sheet=False, \n",
    "                       **to_excel_kwargs):\n",
    "\n",
    "    # Excel file doesn't exist - saving and exiting\n",
    "    if not os.path.isfile(filename):\n",
    "        df.to_excel(\n",
    "            filename,\n",
    "            sheet_name=sheet_name, \n",
    "            startrow=startrow if startrow is not None else 0, \n",
    "            **to_excel_kwargs)\n",
    "        return\n",
    "    \n",
    "    # ignore [engine] parameter if it was passed\n",
    "    if 'engine' in to_excel_kwargs:\n",
    "        to_excel_kwargs.pop('engine')\n",
    "\n",
    "    writer = pd.ExcelWriter(filename, engine='openpyxl', mode='a')\n",
    "\n",
    "    # try to open an existing workbook\n",
    "    writer.book = load_workbook(filename)\n",
    "    \n",
    "    # get the last row in the existing Excel sheet\n",
    "    # if it was not specified explicitly\n",
    "    if startrow is None and sheet_name in writer.book.sheetnames:\n",
    "        startrow = writer.book[sheet_name].max_row\n",
    "\n",
    "    # truncate sheet\n",
    "    if truncate_sheet and sheet_name in writer.book.sheetnames:\n",
    "        # index of [sheet_name] sheet\n",
    "        idx = writer.book.sheetnames.index(sheet_name)\n",
    "        # remove [sheet_name]\n",
    "        writer.book.remove(writer.book.worksheets[idx])\n",
    "        # create an empty sheet [sheet_name] using old index\n",
    "        writer.book.create_sheet(sheet_name, idx)\n",
    "    \n",
    "    # copy existing sheets\n",
    "    writer.sheets = {ws.title:ws for ws in writer.book.worksheets}\n",
    "\n",
    "    if startrow is None:\n",
    "        startrow = 0\n",
    "\n",
    "    # write out the new sheet\n",
    "    df.to_excel(writer, sheet_name, startrow=startrow, **to_excel_kwargs)\n",
    "\n",
    "    # save the workbook\n",
    "    writer.save()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_df_to_excel('lean_in_book.xlsx', df_final, sheet_name='kindle', startrow=None,\n",
    "                       index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check meaning and level [ // development]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = json.load(open(\"dictionary.json\"))\n",
    "# words_book_list = df_words_book.word.tolist()\n",
    "\n",
    "# def closeMatches(patterns, word): \n",
    "# #     print(get_close_matches(word, patterns))\n",
    "  \n",
    "#     if __name__ == \"__main__\":\n",
    "#         matches = []    \n",
    "#         patterns = data\n",
    "#         for word in words_book_list:\n",
    "#             closeMatches(patterns, word)\n",
    "#             matches.append(cell.value)   \n",
    "\n",
    "# dict = PyDictionary() \n",
    "# dictionary=PyDictionary(\"strewn\")\n",
    "# 'There can be any number of words in the Instance'\n",
    "\n",
    "# meaning = dictionary.printMeanings()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
